{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recursos_lexicos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUIG3AGIAtsJg6gF1haL4g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKTYgqTR79Zy"
      },
      "source": [
        "import nltk\n",
        "nltk.download (\"book\")\n",
        "from nltk.book import *\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGaxqlgG8eD4"
      },
      "source": [
        "#Recursos lexicos.\n",
        "Son colocaciones de palabras o frases que tienen asociadas etiquetas o meta-informacion de algun tipo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2VMuzwD85yc",
        "outputId": "b920c3bd-abc6-4e0d-9b78-c7ec929767f7"
      },
      "source": [
        "#Vocabularios: palabras unicas en un corpus\n",
        "vocab = sorted(set(text1))\n",
        "vocab[500:520]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['August',\n",
              " 'Aunt',\n",
              " 'Australia',\n",
              " 'Australian',\n",
              " 'Austrian',\n",
              " 'Author',\n",
              " 'Authors',\n",
              " 'Auto',\n",
              " 'Availing',\n",
              " 'Avast',\n",
              " 'Avatar',\n",
              " 'Aware',\n",
              " 'Away',\n",
              " 'Awful',\n",
              " 'Ay',\n",
              " 'Aye',\n",
              " 'Azores',\n",
              " 'BACK',\n",
              " 'BACKED',\n",
              " 'BACON']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6xkJ6k9aty"
      },
      "source": [
        "#Distribuciones: frecuencia de aparicion\n",
        "word_freq = FreqDist(text1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FofXxVrU9md0",
        "outputId": "c7b146e0-6c07-4e8c-ba41-89dcbb7de7f2"
      },
      "source": [
        "#Stopwords: Palabras muy usadas en el lenguaje que usualmente son filtradas en un pipeline de NLP\n",
        "stopwords.words(\"spanish\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de',\n",
              " 'la',\n",
              " 'que',\n",
              " 'el',\n",
              " 'en',\n",
              " 'y',\n",
              " 'a',\n",
              " 'los',\n",
              " 'del',\n",
              " 'se',\n",
              " 'las',\n",
              " 'por',\n",
              " 'un',\n",
              " 'para',\n",
              " 'con',\n",
              " 'no',\n",
              " 'una',\n",
              " 'su',\n",
              " 'al',\n",
              " 'lo',\n",
              " 'como',\n",
              " 'más',\n",
              " 'pero',\n",
              " 'sus',\n",
              " 'le',\n",
              " 'ya',\n",
              " 'o',\n",
              " 'este',\n",
              " 'sí',\n",
              " 'porque',\n",
              " 'esta',\n",
              " 'entre',\n",
              " 'cuando',\n",
              " 'muy',\n",
              " 'sin',\n",
              " 'sobre',\n",
              " 'también',\n",
              " 'me',\n",
              " 'hasta',\n",
              " 'hay',\n",
              " 'donde',\n",
              " 'quien',\n",
              " 'desde',\n",
              " 'todo',\n",
              " 'nos',\n",
              " 'durante',\n",
              " 'todos',\n",
              " 'uno',\n",
              " 'les',\n",
              " 'ni',\n",
              " 'contra',\n",
              " 'otros',\n",
              " 'ese',\n",
              " 'eso',\n",
              " 'ante',\n",
              " 'ellos',\n",
              " 'e',\n",
              " 'esto',\n",
              " 'mí',\n",
              " 'antes',\n",
              " 'algunos',\n",
              " 'qué',\n",
              " 'unos',\n",
              " 'yo',\n",
              " 'otro',\n",
              " 'otras',\n",
              " 'otra',\n",
              " 'él',\n",
              " 'tanto',\n",
              " 'esa',\n",
              " 'estos',\n",
              " 'mucho',\n",
              " 'quienes',\n",
              " 'nada',\n",
              " 'muchos',\n",
              " 'cual',\n",
              " 'poco',\n",
              " 'ella',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'algunas',\n",
              " 'algo',\n",
              " 'nosotros',\n",
              " 'mi',\n",
              " 'mis',\n",
              " 'tú',\n",
              " 'te',\n",
              " 'ti',\n",
              " 'tu',\n",
              " 'tus',\n",
              " 'ellas',\n",
              " 'nosotras',\n",
              " 'vosotros',\n",
              " 'vosotras',\n",
              " 'os',\n",
              " 'mío',\n",
              " 'mía',\n",
              " 'míos',\n",
              " 'mías',\n",
              " 'tuyo',\n",
              " 'tuya',\n",
              " 'tuyos',\n",
              " 'tuyas',\n",
              " 'suyo',\n",
              " 'suya',\n",
              " 'suyos',\n",
              " 'suyas',\n",
              " 'nuestro',\n",
              " 'nuestra',\n",
              " 'nuestros',\n",
              " 'nuestras',\n",
              " 'vuestro',\n",
              " 'vuestra',\n",
              " 'vuestros',\n",
              " 'vuestras',\n",
              " 'esos',\n",
              " 'esas',\n",
              " 'estoy',\n",
              " 'estás',\n",
              " 'está',\n",
              " 'estamos',\n",
              " 'estáis',\n",
              " 'están',\n",
              " 'esté',\n",
              " 'estés',\n",
              " 'estemos',\n",
              " 'estéis',\n",
              " 'estén',\n",
              " 'estaré',\n",
              " 'estarás',\n",
              " 'estará',\n",
              " 'estaremos',\n",
              " 'estaréis',\n",
              " 'estarán',\n",
              " 'estaría',\n",
              " 'estarías',\n",
              " 'estaríamos',\n",
              " 'estaríais',\n",
              " 'estarían',\n",
              " 'estaba',\n",
              " 'estabas',\n",
              " 'estábamos',\n",
              " 'estabais',\n",
              " 'estaban',\n",
              " 'estuve',\n",
              " 'estuviste',\n",
              " 'estuvo',\n",
              " 'estuvimos',\n",
              " 'estuvisteis',\n",
              " 'estuvieron',\n",
              " 'estuviera',\n",
              " 'estuvieras',\n",
              " 'estuviéramos',\n",
              " 'estuvierais',\n",
              " 'estuvieran',\n",
              " 'estuviese',\n",
              " 'estuvieses',\n",
              " 'estuviésemos',\n",
              " 'estuvieseis',\n",
              " 'estuviesen',\n",
              " 'estando',\n",
              " 'estado',\n",
              " 'estada',\n",
              " 'estados',\n",
              " 'estadas',\n",
              " 'estad',\n",
              " 'he',\n",
              " 'has',\n",
              " 'ha',\n",
              " 'hemos',\n",
              " 'habéis',\n",
              " 'han',\n",
              " 'haya',\n",
              " 'hayas',\n",
              " 'hayamos',\n",
              " 'hayáis',\n",
              " 'hayan',\n",
              " 'habré',\n",
              " 'habrás',\n",
              " 'habrá',\n",
              " 'habremos',\n",
              " 'habréis',\n",
              " 'habrán',\n",
              " 'habría',\n",
              " 'habrías',\n",
              " 'habríamos',\n",
              " 'habríais',\n",
              " 'habrían',\n",
              " 'había',\n",
              " 'habías',\n",
              " 'habíamos',\n",
              " 'habíais',\n",
              " 'habían',\n",
              " 'hube',\n",
              " 'hubiste',\n",
              " 'hubo',\n",
              " 'hubimos',\n",
              " 'hubisteis',\n",
              " 'hubieron',\n",
              " 'hubiera',\n",
              " 'hubieras',\n",
              " 'hubiéramos',\n",
              " 'hubierais',\n",
              " 'hubieran',\n",
              " 'hubiese',\n",
              " 'hubieses',\n",
              " 'hubiésemos',\n",
              " 'hubieseis',\n",
              " 'hubiesen',\n",
              " 'habiendo',\n",
              " 'habido',\n",
              " 'habida',\n",
              " 'habidos',\n",
              " 'habidas',\n",
              " 'soy',\n",
              " 'eres',\n",
              " 'es',\n",
              " 'somos',\n",
              " 'sois',\n",
              " 'son',\n",
              " 'sea',\n",
              " 'seas',\n",
              " 'seamos',\n",
              " 'seáis',\n",
              " 'sean',\n",
              " 'seré',\n",
              " 'serás',\n",
              " 'será',\n",
              " 'seremos',\n",
              " 'seréis',\n",
              " 'serán',\n",
              " 'sería',\n",
              " 'serías',\n",
              " 'seríamos',\n",
              " 'seríais',\n",
              " 'serían',\n",
              " 'era',\n",
              " 'eras',\n",
              " 'éramos',\n",
              " 'erais',\n",
              " 'eran',\n",
              " 'fui',\n",
              " 'fuiste',\n",
              " 'fue',\n",
              " 'fuimos',\n",
              " 'fuisteis',\n",
              " 'fueron',\n",
              " 'fuera',\n",
              " 'fueras',\n",
              " 'fuéramos',\n",
              " 'fuerais',\n",
              " 'fueran',\n",
              " 'fuese',\n",
              " 'fueses',\n",
              " 'fuésemos',\n",
              " 'fueseis',\n",
              " 'fuesen',\n",
              " 'sintiendo',\n",
              " 'sentido',\n",
              " 'sentida',\n",
              " 'sentidos',\n",
              " 'sentidas',\n",
              " 'siente',\n",
              " 'sentid',\n",
              " 'tengo',\n",
              " 'tienes',\n",
              " 'tiene',\n",
              " 'tenemos',\n",
              " 'tenéis',\n",
              " 'tienen',\n",
              " 'tenga',\n",
              " 'tengas',\n",
              " 'tengamos',\n",
              " 'tengáis',\n",
              " 'tengan',\n",
              " 'tendré',\n",
              " 'tendrás',\n",
              " 'tendrá',\n",
              " 'tendremos',\n",
              " 'tendréis',\n",
              " 'tendrán',\n",
              " 'tendría',\n",
              " 'tendrías',\n",
              " 'tendríamos',\n",
              " 'tendríais',\n",
              " 'tendrían',\n",
              " 'tenía',\n",
              " 'tenías',\n",
              " 'teníamos',\n",
              " 'teníais',\n",
              " 'tenían',\n",
              " 'tuve',\n",
              " 'tuviste',\n",
              " 'tuvo',\n",
              " 'tuvimos',\n",
              " 'tuvisteis',\n",
              " 'tuvieron',\n",
              " 'tuviera',\n",
              " 'tuvieras',\n",
              " 'tuviéramos',\n",
              " 'tuvierais',\n",
              " 'tuvieran',\n",
              " 'tuviese',\n",
              " 'tuvieses',\n",
              " 'tuviésemos',\n",
              " 'tuvieseis',\n",
              " 'tuviesen',\n",
              " 'teniendo',\n",
              " 'tenido',\n",
              " 'tenida',\n",
              " 'tenidos',\n",
              " 'tenidas',\n",
              " 'tened']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqJVxE_1-zo1"
      },
      "source": [
        "#Funcion para saber el porcentaje de palabras que no son stopwords en un texto\n",
        "def stopwords_percentage(text):\n",
        "  stopwd = stopwords.words(\"english\")\n",
        "  content = [w for w in text if w.lower() not in stopwd]\n",
        "  return len(content)/len(text)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzWpC4ch_gvT",
        "outputId": "3fe8daa0-076e-47ba-9474-bbf0622136ac"
      },
      "source": [
        "#El 58% del texto tienen palabras que nos son stopwords\n",
        "stopwords_percentage(text1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5862954769399469"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V9B5VwwA2Qw"
      },
      "source": [
        "#Construyendo diccionarios de traduccion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKYvqY2RBCI4",
        "outputId": "87929232-13f9-4b79-b780-2b0d407176a4"
      },
      "source": [
        "from nltk.corpus import swadesh\n",
        "#El id de cada idioma que contiene esta libreria\n",
        "print(swadesh.fileids())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['be', 'bg', 'bs', 'ca', 'cs', 'cu', 'de', 'en', 'es', 'fr', 'hr', 'it', 'la', 'mk', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sw', 'uk']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BktebNpKBVUl",
        "outputId": "c0b93e65-1f1e-43aa-8058-eae36368fa92"
      },
      "source": [
        "print(swadesh.words(\"en\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'you (singular), thou', 'he', 'we', 'you (plural)', 'they', 'this', 'that', 'here', 'there', 'who', 'what', 'where', 'when', 'how', 'not', 'all', 'many', 'some', 'few', 'other', 'one', 'two', 'three', 'four', 'five', 'big', 'long', 'wide', 'thick', 'heavy', 'small', 'short', 'narrow', 'thin', 'woman', 'man (adult male)', 'man (human being)', 'child', 'wife', 'husband', 'mother', 'father', 'animal', 'fish', 'bird', 'dog', 'louse', 'snake', 'worm', 'tree', 'forest', 'stick', 'fruit', 'seed', 'leaf', 'root', 'bark (from tree)', 'flower', 'grass', 'rope', 'skin', 'meat', 'blood', 'bone', 'fat (noun)', 'egg', 'horn', 'tail', 'feather', 'hair', 'head', 'ear', 'eye', 'nose', 'mouth', 'tooth', 'tongue', 'fingernail', 'foot', 'leg', 'knee', 'hand', 'wing', 'belly', 'guts', 'neck', 'back', 'breast', 'heart', 'liver', 'drink', 'eat', 'bite', 'suck', 'spit', 'vomit', 'blow', 'breathe', 'laugh', 'see', 'hear', 'know (a fact)', 'think', 'smell', 'fear', 'sleep', 'live', 'die', 'kill', 'fight', 'hunt', 'hit', 'cut', 'split', 'stab', 'scratch', 'dig', 'swim', 'fly (verb)', 'walk', 'come', 'lie', 'sit', 'stand', 'turn', 'fall', 'give', 'hold', 'squeeze', 'rub', 'wash', 'wipe', 'pull', 'push', 'throw', 'tie', 'sew', 'count', 'say', 'sing', 'play', 'float', 'flow', 'freeze', 'swell', 'sun', 'moon', 'star', 'water', 'rain', 'river', 'lake', 'sea', 'salt', 'stone', 'sand', 'dust', 'earth', 'cloud', 'fog', 'sky', 'wind', 'snow', 'ice', 'smoke', 'fire', 'ashes', 'burn', 'road', 'mountain', 'red', 'green', 'yellow', 'white', 'black', 'night', 'day', 'year', 'warm', 'cold', 'full', 'new', 'old', 'good', 'bad', 'rotten', 'dirty', 'straight', 'round', 'sharp', 'dull', 'smooth', 'wet', 'dry', 'correct', 'near', 'far', 'right', 'left', 'at', 'in', 'with', 'and', 'if', 'because', 'name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytai2C1MBbO7",
        "outputId": "fa0ca623-672a-4d8c-c61b-c0f9310f4cb6"
      },
      "source": [
        "#Hacemos una lista que contiene todas las traducciones de las palabras de ingles a español\n",
        "en2es = swadesh.entries([\"en\", \"es\"])\n",
        "print(en2es)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'yo'), ('you (singular), thou', 'tú, usted'), ('he', 'él'), ('we', 'nosotros'), ('you (plural)', 'vosotros, ustedes'), ('they', 'ellos, ellas'), ('this', 'este'), ('that', 'ese, aquel'), ('here', 'aquí, acá'), ('there', 'ahí, allí, allá'), ('who', 'quien'), ('what', 'que'), ('where', 'donde'), ('when', 'cuando'), ('how', 'como'), ('not', 'no'), ('all', 'todo'), ('many', 'muchos'), ('some', 'algunos, unos'), ('few', 'poco'), ('other', 'otro'), ('one', 'uno'), ('two', 'dos'), ('three', 'tres'), ('four', 'cuatro'), ('five', 'cinco'), ('big', 'grande'), ('long', 'largo'), ('wide', 'ancho'), ('thick', 'gordo'), ('heavy', 'pesado'), ('small', 'pequeño'), ('short', 'corto'), ('narrow', 'estrecho, angosto'), ('thin', 'delgado, flaco'), ('woman', 'mujer'), ('man (adult male)', 'hombre'), ('man (human being)', 'hombre'), ('child', 'niño'), ('wife', 'esposa, mujer'), ('husband', 'esposo, marido'), ('mother', 'madre'), ('father', 'padre'), ('animal', 'animal'), ('fish', 'pez, pescado'), ('bird', 'ave, pájaro'), ('dog', 'perro'), ('louse', 'piojo'), ('snake', 'serpiente, culebra'), ('worm', 'gusano'), ('tree', 'árbol'), ('forest', 'bosque'), ('stick', 'palo'), ('fruit', 'fruta'), ('seed', 'semilla'), ('leaf', 'hoja'), ('root', 'raíz'), ('bark (from tree)', 'corteza'), ('flower', 'flor'), ('grass', 'hierba, pasto'), ('rope', 'cuerda'), ('skin', 'piel'), ('meat', 'carne'), ('blood', 'sangre'), ('bone', 'hueso'), ('fat (noun)', 'grasa'), ('egg', 'huevo'), ('horn', 'cuerno'), ('tail', 'cola'), ('feather', 'pluma'), ('hair', 'cabello, pelo'), ('head', 'cabeza'), ('ear', 'oreja'), ('eye', 'ojo'), ('nose', 'nariz'), ('mouth', 'boca'), ('tooth', 'diente'), ('tongue', 'lengua'), ('fingernail', 'uña'), ('foot', 'pie'), ('leg', 'pierna'), ('knee', 'rodilla'), ('hand', 'mano'), ('wing', 'ala'), ('belly', 'barriga, vientre, panza'), ('guts', 'entrañas, tripas'), ('neck', 'cuello'), ('back', 'espalda'), ('breast', 'pecho, seno'), ('heart', 'corazón'), ('liver', 'hígado'), ('drink', 'beber, tomar'), ('eat', 'comer'), ('bite', 'morder'), ('suck', 'chupar'), ('spit', 'escupir'), ('vomit', 'vomitar'), ('blow', 'soplar'), ('breathe', 'respirar'), ('laugh', 'reír'), ('see', 'ver'), ('hear', 'oír'), ('know (a fact)', 'saber'), ('think', 'pensar'), ('smell', 'oler'), ('fear', 'temer'), ('sleep', 'dormir'), ('live', 'vivir'), ('die', 'morir'), ('kill', 'matar'), ('fight', 'pelear'), ('hunt', 'cazar'), ('hit', 'golpear'), ('cut', 'cortar'), ('split', 'partir'), ('stab', 'apuñalar'), ('scratch', 'arañar, rascar'), ('dig', 'cavar'), ('swim', 'nadar'), ('fly (verb)', 'volar'), ('walk', 'caminar'), ('come', 'venir'), ('lie', 'echarse, acostarse, tenderse'), ('sit', 'sentarse'), ('stand', 'estar de pie'), ('turn', 'voltear'), ('fall', 'caer'), ('give', 'dar'), ('hold', 'sostener'), ('squeeze', 'apretar'), ('rub', 'frotar'), ('wash', 'lavar'), ('wipe', 'limpiar'), ('pull', 'tirar'), ('push', 'empujar'), ('throw', 'tirar'), ('tie', 'atar'), ('sew', 'coser'), ('count', 'contar'), ('say', 'decir'), ('sing', 'cantar'), ('play', 'jugar'), ('float', 'flotar'), ('flow', 'fluir'), ('freeze', 'helar'), ('swell', 'hincharse'), ('sun', 'sol'), ('moon', 'luna'), ('star', 'estrella'), ('water', 'agua'), ('rain', 'lluvia'), ('river', 'río'), ('lake', 'lago'), ('sea', 'mar'), ('salt', 'sal'), ('stone', 'piedra'), ('sand', 'arena'), ('dust', 'polvo'), ('earth', 'tierra'), ('cloud', 'nube'), ('fog', 'niebla'), ('sky', 'cielo'), ('wind', 'viento'), ('snow', 'nieve'), ('ice', 'hielo'), ('smoke', 'humo'), ('fire', 'fuego'), ('ashes', 'cenizas'), ('burn', 'quemar'), ('road', 'camino'), ('mountain', 'montaña'), ('red', 'rojo'), ('green', 'verde'), ('yellow', 'amarillo'), ('white', 'blanco'), ('black', 'negro'), ('night', 'noche'), ('day', 'día'), ('year', 'año'), ('warm', 'cálido, tibio'), ('cold', 'frío'), ('full', 'lleno'), ('new', 'nuevo'), ('old', 'viejo'), ('good', 'bueno'), ('bad', 'malo'), ('rotten', 'podrido'), ('dirty', 'sucio'), ('straight', 'recto'), ('round', 'redondo'), ('sharp', 'afilado'), ('dull', 'desafilado'), ('smooth', 'suave, liso'), ('wet', 'mojado'), ('dry', 'seco'), ('correct', 'correcto'), ('near', 'cerca'), ('far', 'lejos'), ('right', 'derecha'), ('left', 'izquierda'), ('at', 'a, en, ante'), ('in', 'en'), ('with', 'con'), ('and', 'y'), ('if', 'si'), ('because', 'porque'), ('name', 'nombre')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pOMy17pzBy8z",
        "outputId": "2f3cb841-1031-448b-b1fe-8cac8f77749d"
      },
      "source": [
        "#Hacemos un diccionario para traducir\n",
        "translate = dict(en2es)\n",
        "translate[\"how\"]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'como'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuxtlM6OHqnC"
      },
      "source": [
        "#Wordnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-gkHBC7HuyR",
        "outputId": "3d57df7e-f09e-4674-bdf9-6835b711290e"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"omw\")\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Aj-QT_0H-9y",
        "outputId": "b0ca66bf-5006-4e76-d3b5-69bfc04e50f3"
      },
      "source": [
        "#Synset: grupo sinonimos\n",
        "ss = wn.synsets(\"carro\",  lang= \"spa\")\n",
        "ss"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('car.n.01'),\n",
              " Synset('carriage.n.04'),\n",
              " Synset('carrier.n.02'),\n",
              " Synset('cart.n.01'),\n",
              " Synset('chariot.n.02'),\n",
              " Synset('cartload.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb1vYkOuI1Ev",
        "outputId": "ca599b1d-15ef-4f6b-dc20-3c83b018bc5c"
      },
      "source": [
        "#Exploramos synsets\n",
        "for syn in ss:\n",
        "  print(syn.name(), \":\", syn.definition())\n",
        "  for name in syn.lemma_names():\n",
        "    print(\"*\", name)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car.n.01 : a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
            "* car\n",
            "* auto\n",
            "* automobile\n",
            "* machine\n",
            "* motorcar\n",
            "carriage.n.04 : a machine part that carries something else\n",
            "* carriage\n",
            "carrier.n.02 : a self-propelled wheeled vehicle designed specifically to carry something\n",
            "* carrier\n",
            "cart.n.01 : a heavy open wagon usually having two wheels and drawn by an animal\n",
            "* cart\n",
            "chariot.n.02 : a two-wheeled horse-drawn battle vehicle; used in war and races in ancient Egypt and Greece and Rome\n",
            "* chariot\n",
            "cartload.n.01 : the quantity that a cart holds\n",
            "* cartload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni9aIVlAJVf8"
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "#Creamos funciones importantes\n",
        "def closure_graph(synset, fn):\n",
        "  seen = set()\n",
        "  graph = nx.DiGraph()\n",
        "  labels = {}\n",
        "\n",
        "def recurse(s):\n",
        "  if not s in seen:\n",
        "    seen.add(s)\n",
        "    labels[s.name] = s.name().split(\".\")[0]\n",
        "    graph.add_node(s.name)\n",
        "    for s1 in fn(s):\n",
        "      graph.add_node(s1.name)\n",
        "      graph.add_edge(s.name, s1.name)\n",
        "      recurse(s1)\n",
        "  \n",
        "  recurse(sysnset)\n",
        "  return graph, labels\n",
        "\n",
        "def draw_text_graph(G, labels):\n",
        "  plt.figure(figsize=(18,12))\n",
        "  pos = nx.planar_layout(G, scale=18)\n",
        "  nx.draw_networkx_nodes(G, pos, node_color=\"red\", linewidths=0, node_size=500)\n",
        "  nx.draw_networkx_labels(G, pos, font_size=20, labels=labels)\n",
        "  nx.draw_networkx_edges(G, pos)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edQnYOomLXzj"
      },
      "source": [
        "#Hyponyms: Conceptos que son más especificos que la palabra raiz de la cual derivan "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPfDtqwLLpuI",
        "outputId": "1cd2b753-a2b8-4f48-e329-07e930402120"
      },
      "source": [
        "#Muestra los hyponyms que tiene esa palabra\n",
        "ss[0].hyponyms()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('ambulance.n.01'),\n",
              " Synset('beach_wagon.n.01'),\n",
              " Synset('bus.n.04'),\n",
              " Synset('cab.n.03'),\n",
              " Synset('compact.n.03'),\n",
              " Synset('convertible.n.01'),\n",
              " Synset('coupe.n.01'),\n",
              " Synset('cruiser.n.01'),\n",
              " Synset('electric.n.01'),\n",
              " Synset('gas_guzzler.n.01'),\n",
              " Synset('hardtop.n.01'),\n",
              " Synset('hatchback.n.01'),\n",
              " Synset('horseless_carriage.n.01'),\n",
              " Synset('hot_rod.n.01'),\n",
              " Synset('jeep.n.01'),\n",
              " Synset('limousine.n.01'),\n",
              " Synset('loaner.n.02'),\n",
              " Synset('minicar.n.01'),\n",
              " Synset('minivan.n.01'),\n",
              " Synset('model_t.n.01'),\n",
              " Synset('pace_car.n.01'),\n",
              " Synset('racer.n.02'),\n",
              " Synset('roadster.n.01'),\n",
              " Synset('sedan.n.01'),\n",
              " Synset('sport_utility.n.01'),\n",
              " Synset('sports_car.n.01'),\n",
              " Synset('stanley_steamer.n.01'),\n",
              " Synset('stock_car.n.01'),\n",
              " Synset('subcompact.n.01'),\n",
              " Synset('touring_car.n.01'),\n",
              " Synset('used-car.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "t9VfHDWrMxyB",
        "outputId": "984a76f4-0d0d-40b9-edd3-2ca37943efe8"
      },
      "source": [
        "#Este no se porque no me funciona, me da un error TypeError: cannot unpack non-iterable NoneType object\n",
        "G, labels = closure_graph(ss[0], fn = lambda s: s.hyponyms())\n",
        "draw_text_graph(G, labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0fe88a2249bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdraw_text_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB9nLQd_MJWY"
      },
      "source": [
        "#Hypernyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIXBqgkNMRCa",
        "outputId": "55b5c480-5c06-4901-cfdf-b1e06a8d056a"
      },
      "source": [
        "ss[0].hypernyms()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('motor_vehicle.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "j8-IDwuiPhRN",
        "outputId": "000304b5-1b9e-479d-b649-be82e65a2c15"
      },
      "source": [
        "#Este no se porque no me funciona, me da un error TypeError: cannot unpack non-iterable NoneType object\n",
        "G, labels = closure_graph(ss[0], fn = lambda s: s.hypernyms())\n",
        "draw_text_graph(G, labels)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f78d52e66e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdraw_text_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgAttThKSVmD"
      },
      "source": [
        "#Similitud Semantica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHJvFc_wSerT"
      },
      "source": [
        "def show_syns(word):\n",
        "  ss = wn.synsets(word, lang = \"spa\")\n",
        "  for syn in ss:\n",
        "    print(syn.name(), \" : \", syn.definition())\n",
        "    for name in syn.lemma_names():\n",
        "      print(\" * \", name)\n",
        "  return ss"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAlVcekSS8G4",
        "outputId": "9b01f30f-4a1f-4028-c44b-29ada7005ff6"
      },
      "source": [
        "ss = show_syns(\"perro\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog.n.01  :  a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
            " *  dog\n",
            " *  domestic_dog\n",
            " *  Canis_familiaris\n",
            "rotter.n.01  :  a person who is deemed to be despicable or contemptible\n",
            " *  rotter\n",
            " *  dirty_dog\n",
            " *  rat\n",
            " *  skunk\n",
            " *  stinker\n",
            " *  stinkpot\n",
            " *  bum\n",
            " *  puke\n",
            " *  crumb\n",
            " *  lowlife\n",
            " *  scum_bag\n",
            " *  so-and-so\n",
            " *  git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZ9rpprTF5f",
        "outputId": "23623bb0-eabb-44cf-942d-d6c90bf2f77d"
      },
      "source": [
        "ss2 = show_syns(\"gato\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat.n.01  :  feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
            " *  cat\n",
            " *  true_cat\n",
            "tom.n.02  :  male cat\n",
            " *  tom\n",
            " *  tomcat\n",
            "dodger.n.01  :  a shifty deceptive person\n",
            " *  dodger\n",
            " *  fox\n",
            " *  slyboots\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwdXFFxnTZ2E",
        "outputId": "9c65bc89-5969-47e5-b680-31f1b9ae6556"
      },
      "source": [
        "ss3 = show_syns(\"animal\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "animal.n.01  :  a living organism characterized by voluntary movement\n",
            " *  animal\n",
            " *  animate_being\n",
            " *  beast\n",
            " *  brute\n",
            " *  creature\n",
            " *  fauna\n",
            "beast.n.02  :  a cruelly rapacious person\n",
            " *  beast\n",
            " *  wolf\n",
            " *  savage\n",
            " *  brute\n",
            " *  wildcat\n",
            "dunce.n.01  :  a stupid person; these words are used to express a low opinion of someone's intelligence\n",
            " *  dunce\n",
            " *  dunderhead\n",
            " *  numskull\n",
            " *  blockhead\n",
            " *  bonehead\n",
            " *  lunkhead\n",
            " *  hammerhead\n",
            " *  knucklehead\n",
            " *  loggerhead\n",
            " *  muttonhead\n",
            " *  shithead\n",
            " *  dumbass\n",
            " *  fuckhead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xds-Qj6MTl34"
      },
      "source": [
        "perro = ss[0]\n",
        "gato = ss2[0]\n",
        "animal = ss3[0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRLt-8_-TzKb",
        "outputId": "3789f437-9094-41e5-c4fe-3a5208483464"
      },
      "source": [
        "#Comparamos la similitud semantica\n",
        "animal.path_similarity(perro)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA3dFd0bT7vW",
        "outputId": "b948c3ff-e28e-43e6-efa2-75cda198ab95"
      },
      "source": [
        "animal.path_similarity(gato)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.125"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J36m2DgkUBBW",
        "outputId": "161f917a-9184-418b-bb07-a0e9663fb799"
      },
      "source": [
        "animal.path_similarity(animal)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}